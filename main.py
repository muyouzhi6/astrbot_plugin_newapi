import asyncio
import json
import os
import time
from datetime import datetime, timezone, timedelta
from typing import Any, Dict, List, Tuple, Optional
from pathlib import Path

import astrbot.api.message_components as Comp
from astrbot.api import logger, AstrBotConfig
from astrbot.api.event import AstrMessageEvent, filter
from astrbot.api.star import Context, Star, register


@register(
    "newapi",
    "æ«",
    "ä»å¯é…ç½®çš„API æ‹‰å–ç”¨é‡æ•°æ®ï¼ŒæŒ‰å›ºå®šæ—¶é—´è·¨åº¦ç»Ÿè®¡ RPM/TPM/TopN æ¨¡å‹ï¼Œå¹¶åœ¨èŠå¤©ä¸­è¿”å›æŠ¥å‘Š",
    "1.0.0",
)
class XiguaUsageReporter(Star):
    """
    ä¸€ä¸ª AstrBot æ’ä»¶ï¼š
    - é€šè¿‡å¯é…ç½®çš„ `base_url`ã€`Authorization`ã€`New-Api-User` è¯·æ±‚ä¸Šæ¸¸ API
    - ä½¿ç”¨å›ºå®šçš„æ—¶é—´è·¨åº¦ï¼ˆåˆ†é’Ÿï¼‰å¯¹æ•°æ®è¿›è¡Œèšåˆè®¡ç®—
    - è¾“å‡ºæ€»ä½¿ç”¨é‡ã€æ€»è¯·æ±‚æ•°ã€æ€»é…é¢ã€å¹³å‡ RPM/TPMï¼Œä»¥åŠä½¿ç”¨é‡ Top N çš„æ¨¡å‹
    - å¯é€‰å°†åŸå§‹ JSON å“åº”ä¿å­˜åˆ°æ’ä»¶ç›®å½•ä¸‹çš„ `data.json`
    - å›ºå®šä½¿ç”¨é…ç½®ä¸­çš„ `time_span_minutes`ï¼ˆé»˜è®¤ 1500 åˆ†é’Ÿ = 25 å°æ—¶ï¼‰
    """

    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        # æœ¬æ’ä»¶ç›®å½•ä¸æ•°æ®æ–‡ä»¶è·¯å¾„
        self._plugin_dir: Path = Path(__file__).resolve().parent
        self.data_file_path: Path = self._plugin_dir / "data.json"
        # åŸºç¡€è¯·æ±‚é…ç½®ï¼ˆä»…åŸŸå + å¯é…ç½®è·¯å¾„ï¼‰
        self.base_domain: str = (
            config.get("base_domain")
            or config.get("base_url")  # å…¼å®¹æ—§å­—æ®µ
            or "https://new.xigua.wiki"
        ).strip()
        # æ¥å£è·¯å¾„å›ºå®šä¸ºæœ¬æ’ä»¶çš„é»˜è®¤å€¼ï¼Œé…ç½®æ–‡ä»¶ä¸å†æä¾›è·¯å¾„é¡¹
        self.endpoint_path: str = "/api/data/self"
        self.authorization: str = config.get("authorization", "").strip()
        self.new_api_user: str = config.get("new_api_user", "").strip()
        self.request_timeout: int = int(config.get("request_timeout", 15))

        # ç»Ÿè®¡ä¸å±•ç¤ºé…ç½®
        self.time_span_minutes_default: int = 1500
        self.show_top_models: bool = bool(config.get("show_top_models", True))
        try:
            self.top_n_models: int = int(config.get("top_n_models", 3))
        except Exception:
            self.top_n_models = 3
        self.save_raw_json: bool = True
        # æ˜¯å¦ä½¿ç”¨åˆå¹¶è½¬å‘å‘é€ï¼ˆå…è®¸é€šè¿‡é…ç½®å¼€å…³ï¼‰
        try:
            self.use_forward: bool = bool(config.get("use_forward", True))
        except Exception:
            self.use_forward = True
        self.log_verbose: bool = True
        self.max_log_body_chars: int = 500
        # è®°å½•æœ€è¿‘ä¸€æ¬¡æ„é€ çš„æ—¶é—´çª—ï¼Œä¾¿äºæ—¥å¿—æ ¸å¯¹
        self._last_start_ts: int = 0
        self._last_end_ts: int = 0

        # æ—¥å¿—æŸ¥è¯¢é…ç½®
        try:
            self.log_page_size: int = int(config.get("log_page_size", 20))
        except Exception:
            self.log_page_size = 20
        try:
            self.log_use_forward: bool = bool(config.get("log_use_forward", self.use_forward))
        except Exception:
            self.log_use_forward = self.use_forward
        try:
            self.user_use_forward: bool = bool(config.get("user_use_forward", False))
        except Exception:
            self.user_use_forward = False

        logger.info(
            f"å·²åŠ è½½ [XiguaUsageReporter] v1.0.0ï¼Œé»˜è®¤ç»Ÿè®¡ {self.time_span_minutes_default} åˆ†é’Ÿï¼ŒTop{self.top_n_models} æ¨¡å‹ã€‚"
        )

    async def _http_get_json(self, url: str, headers: Dict[str, str]) -> Dict[str, Any]:
        """ä½¿ç”¨æ ‡å‡†åº“å‘èµ· GET è¯·æ±‚å¹¶è§£æ JSONï¼Œé¿å…é¢å¤–ä¾èµ–ã€‚"""
        from urllib.request import Request, urlopen
        from urllib.error import URLError, HTTPError

        if self.log_verbose:
            masked_headers = dict(headers)
            if "Authorization" in masked_headers:
                masked_headers["Authorization"] = self._mask_secret(masked_headers["Authorization"])
            if "New-Api-User" in masked_headers:
                masked_headers["New-Api-User"] = self._mask_secret(str(masked_headers["New-Api-User"]))
            logger.debug(f"HTTP GET å³å°†è¯·æ±‚: url={url}, headers={masked_headers}")

        req = Request(url=url, method="GET")
        for k, v in headers.items():
            req.add_header(k, v)

        def _do() -> Dict[str, Any]:
            with urlopen(req, timeout=self.request_timeout) as resp:
                status = getattr(resp, "status", None)
                if status is None:
                    try:
                        status = resp.getcode()
                    except Exception:
                        status = -1
                ct = None
                try:
                    ct = resp.headers.get("Content-Type")
                except Exception:
                    ct = None
                data = resp.read()
                body_len = len(data) if data else 0
                if self.log_verbose:
                    logger.debug(f"HTTP å“åº”: status={status}, content_type={ct}, body_len={body_len}")
                # å°è¯•è§£æ JSON
                text = None
                try:
                    text = data.decode("utf-8", errors="ignore")
                except Exception:
                    pass
                try:
                    return json.loads(text if text is not None else data)
                except Exception as e:
                    if self.log_verbose:
                        snippet = (text or "")[: self.max_log_body_chars]
                        logger.debug(f"HTTP å“åº”é JSONï¼Œè§£æå¤±è´¥: {e}; ç‰‡æ®µ: {snippet}")
                    return {"error": "non_json_response", "status": status, "content_type": ct}

        try:
            result = await asyncio.to_thread(_do)
            if self.log_verbose:
                if isinstance(result, dict):
                    logger.debug(f"HTTP å“åº”å·²è§£æä¸º JSON å¯¹è±¡ï¼Œé¡¶å±‚é”®: {list(result.keys())[:20]}")
                elif isinstance(result, list):
                    logger.debug(f"HTTP å“åº”å·²è§£æä¸º JSON åˆ—è¡¨ï¼Œé•¿åº¦: {len(result)}")
                else:
                    logger.debug(f"HTTP å“åº”å·²è§£æä¸º JSONï¼Œç±»å‹: {type(result).__name__}")
            return result
        except HTTPError as e:
            text = f"HTTP {e.code} {e.reason}"
            logger.error(f"è¯·æ±‚å¤±è´¥: {text}")
            return {"error": text}
        except URLError as e:
            text = f"URL é”™è¯¯: {e.reason}"
            logger.error(f"è¯·æ±‚å¤±è´¥: {text}")
            return {"error": text}
        except Exception as e:
            text = f"è¯·æ±‚å¼‚å¸¸: {e}"
            logger.error(text)
            return {"error": text}

    def _extract_records(self, payload: Any) -> List[Dict[str, Any]]:
        """æ›´å®½æ¾åœ°æå–è®°å½•åˆ—è¡¨ï¼Œå…¼å®¹å¤šç§è¿”å›æ ¼å¼ï¼Œå¹¶è¾“å‡ºè¯¦ç»†æ—¥å¿—ã€‚"""
        try:
            ptype = type(payload).__name__
            if self.log_verbose:
                logger.debug(f"extract_records: é¡¶å±‚ç±»å‹={ptype}")
            # ç›´æ¥æ˜¯åˆ—è¡¨
            if isinstance(payload, list):
                if self.log_verbose:
                    logger.debug(f"extract_records: ä½¿ç”¨é¡¶å±‚åˆ—è¡¨ï¼Œlen={len(payload)}")
                return payload  # type: ignore
            if not isinstance(payload, dict):
                return []
            # å¸¸è§ï¼šdata ä¸ºåˆ—è¡¨
            data = payload.get("data")
            if isinstance(data, list):
                if self.log_verbose:
                    logger.debug(f"extract_records: ä½¿ç”¨ data(list)ï¼Œlen={len(data)}")
                return data  # type: ignore
            # data ä¸ºå¯¹è±¡ï¼Œå…¶ä¸­å†åŒ…å« data/list
            if isinstance(data, dict):
                inner = data.get("data")
                if isinstance(inner, list):
                    if self.log_verbose:
                        logger.debug(f"extract_records: ä½¿ç”¨ data.data(list)ï¼Œlen={len(inner)}")
                    return inner  # type: ignore
                inner = data.get("list")
                if isinstance(inner, list):
                    if self.log_verbose:
                        logger.debug(f"extract_records: ä½¿ç”¨ data.list(list)ï¼Œlen={len(inner)}")
                    return inner  # type: ignore
            # é¡¶å±‚ list
            lst = payload.get("list")
            if isinstance(lst, list):
                if self.log_verbose:
                    logger.debug(f"extract_records: ä½¿ç”¨ list(list)ï¼Œlen={len(lst)}")
                return lst  # type: ignore
            if self.log_verbose:
                logger.debug("extract_records: æœªåœ¨å¸¸è§è·¯å¾„å‘ç°åˆ—è¡¨ï¼Œè¿”å›ç©º")
            return []
        except Exception as e:
            logger.warning(f"extract_records: è§£æå¼‚å¸¸: {e}")
            return []

    def _analyze(self, records: List[Dict[str, Any]], start_timestamp: int, end_timestamp: int, time_span_minutes: int) -> Tuple[Dict[str, Any], List[Tuple[str, Dict[str, int]]]]:
        """ä½¿ç”¨å½“å‰æ—¶åˆ»å›æº¯çš„å›ºå®šçª—å£ [start_timestamp, end_timestamp] è¿›è¡Œç»Ÿè®¡ï¼›å¹³å‡å€¼ä»¥ time_span_minutes ä¸ºåˆ†æ¯ã€‚"""
        if start_timestamp <= 0 or end_timestamp <= 0 or end_timestamp < start_timestamp:
            end_timestamp = int(time.time())
            start_timestamp = end_timestamp - (time_span_minutes * 60)

        total_tokens_used = 0
        total_requests = 0
        total_quota = 0

        model_stats: Dict[str, Dict[str, int]] = {}

        for r in records:
            created_at = int(r.get("created_at", 0) or 0)
            if start_timestamp <= created_at <= end_timestamp:
                model_name = r.get("model_name")
                tokens_used = int(r.get("token_used", 0) or 0)
                count = int(r.get("count", 0) or 0)
                quota = int(r.get("quota", 0) or 0)

                total_tokens_used += tokens_used
                total_requests += count
                total_quota += quota

                if model_name:
                    entry = model_stats.setdefault(model_name, {"total_tokens": 0, "total_requests": 0, "total_quota": 0})
                    entry["total_tokens"] += tokens_used
                    entry["total_requests"] += count
                    entry["total_quota"] += quota

        minutes_for_avg = max(1, int(time_span_minutes))
        avg_rpm = (total_requests / minutes_for_avg) if minutes_for_avg > 0 else 0.0
        avg_tpm = (total_tokens_used / minutes_for_avg) if minutes_for_avg > 0 else 0.0

        stats = {
            "time_span_minutes": time_span_minutes,
            "start_timestamp": start_timestamp,
            "end_timestamp": end_timestamp,
            "total_tokens_used": total_tokens_used,
            "total_requests": total_requests,
            "total_quota": total_quota,
            "avg_rpm": avg_rpm,
            "avg_tpm": avg_tpm,
        }

        # è°ƒç”¨æœ€å¤šï¼ˆæŒ‰è¯·æ±‚æ¬¡æ•°ï¼‰æ’åº
        sorted_models = sorted(model_stats.items(), key=lambda kv: kv[1]["total_requests"], reverse=True)
        return stats, sorted_models

    @staticmethod
    def _fmt_ts(ts: int) -> str:
        if not ts:
            return "-"
        try:
            tz = timezone(timedelta(hours=8), name="CST+8")
            return datetime.fromtimestamp(ts, tz).strftime("%Y-%m-%d %H:%M:%S %Z")
        except Exception:
            return str(ts)

    def _format_report(self, stats: Dict[str, Any], sorted_models: List[Tuple[str, Dict[str, int]]]) -> str:
        start_time_str = self._fmt_ts(int(stats.get("start_timestamp", 0)))
        end_time_str = self._fmt_ts(int(stats.get("end_timestamp", 0)))
        span_minutes = float(stats.get("time_span_minutes", 0.0) or 0.0)
        lines = [
            "--- æ•°æ®åˆ†ææŠ¥å‘Š ---",
            f"è®¡ç®—æ—¶é—´è·¨åº¦: {int(span_minutes)} åˆ†é’Ÿ",
            f"æ•°æ®èŒƒå›´: {start_time_str} è‡³ {end_time_str}",
            f"æ€»ä½¿ç”¨é‡ (tokens): {stats.get('total_tokens_used', 0):,}",
            f"æ€»è¯·æ±‚æ¬¡æ•°: {stats.get('total_requests', 0):,}",
            f"æ€»é…é¢: {stats.get('total_quota', 0):,}",
            f"å¹³å‡ RPM: {float(stats.get('avg_rpm', 0.0)):.3f}",
            f"å¹³å‡ TPM: {float(stats.get('avg_tpm', 0.0)):.3f}",
            "-------------------------",
        ]

        if self.show_top_models and self.top_n_models > 0 and sorted_models:
            lines.append(f"è°ƒç”¨æœ€å¤šçš„å‰ {self.top_n_models} ä¸ªæ¨¡å‹ï¼š")
            span_minutes_float = max(1e-9, float(stats.get("time_span_minutes", 0.0) or 0.0))
            for model, s in sorted_models[: self.top_n_models]:
                avg_tpm_model = (s["total_tokens"] / span_minutes_float) if span_minutes_float > 0 else 0.0
                avg_rpm_model = (s["total_requests"] / span_minutes_float) if span_minutes_float > 0 else 0.0
                lines.append("")
                lines.append(f"æ¨¡å‹: {model}")
                lines.append(f"  - Tokenæ€»å’Œ: {s['total_tokens']:,}")
                lines.append(f"  - è¯·æ±‚æ€»æ•°: {s['total_requests']:,}")
                lines.append(f"  - å¹³å‡ TPM: {avg_tpm_model:.3f}")
                lines.append(f"  - å¹³å‡ RPM: {avg_rpm_model:.3f}")
                lines.append(f"  - é…é¢: {s['total_quota']:,}")
            lines.append("")
            lines.append(f"æ¨¡å‹: {model}")
            lines.append(f"  - Tokenæ€»å’Œ: {s['total_tokens']:,}")
            lines.append(f"  - è¯·æ±‚æ€»æ•°: {s['total_requests']:,}")
            lines.append(f"  - å¹³å‡ TPM: {avg_tpm_model:.3f}")
            lines.append(f"  - å¹³å‡ RPM: {avg_rpm_model:.3f}")
            lines.append(f"  - é…é¢: {s['total_quota']:,}")

        return "\n".join(lines)

    @staticmethod
    def _mask_secret(value: str, left: int = 4, right: int = 2) -> str:
        try:
            v = str(value)
            if len(v) <= left + right:
                return "*" * len(v)
            return v[:left] + "..." + v[-right:]
        except Exception:
            return "***"

    def _build_forward_node(self, text: str) -> Any:
        """å°†æ–‡æœ¬åŒ…è£…ä¸ºåˆå¹¶è½¬å‘ Nodeã€‚"""
        try:
            conf_uin = getattr(self, "forward_uin", None)
            if conf_uin is None and hasattr(self, "config"):
                conf_uin = self.config.get("forward_uin")  # type: ignore
            forward_uin = int(conf_uin) if conf_uin not in (None, "", 0) else 10000
        except Exception:
            forward_uin = 10000
        forward_name = getattr(self, "forward_name", None) or (
            getattr(self, "config", {}).get("forward_name") if hasattr(self, "config") else None  # type: ignore
        ) or "xuxue07 Bot"
        return Comp.Node(
            uin=forward_uin,
            name=forward_name,
            content=[Comp.Plain(text)],
        )

    def _build_forward_nodes(self, text: str) -> List[Any]:
        """å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºå¤šæ®µï¼Œç”Ÿæˆå¤šä¸ª Nodeã€‚"""
        max_len = 900
        parts: List[str] = []
        t = text or ""
        while t:
            parts.append(t[:max_len])
            t = t[max_len:]
        if not parts:
            parts = ["(ç©º)"]
        nodes = [self._build_forward_node(p) for p in parts]
        return nodes

    async def _save_raw_json(self, payload: Dict[str, Any]):
        if not self.save_raw_json:
            return
        try:
            with open(self.data_file_path, "w", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False)
            if self.log_verbose:
                try:
                    size = self.data_file_path.stat().st_size
                    logger.debug(f"å·²ä¿å­˜åŸå§‹ JSON åˆ° {self.data_file_path} (size={size} bytes)")
                except Exception:
                    logger.debug(f"å·²ä¿å­˜åŸå§‹ JSON åˆ° {self.data_file_path}")
        except Exception as e:
            logger.warning(f"ä¿å­˜ data.json å¤±è´¥: {e}")

    async def _load_local_json(self) -> Dict[str, Any]:
        try:
            if self.log_verbose:
                logger.debug(f"å°è¯•ä»æœ¬åœ°è¯»å–: {self.data_file_path} (exists={self.data_file_path.exists()})")
            with open(self.data_file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
        except Exception as e:
            logger.warning(f"è¯»å– data.json å¤±è´¥: {e}")
            return {}

    def _build_headers(self) -> Dict[str, str]:
        headers = {
            "Accept": "application/json",
        }
        if self.authorization:
            headers["Authorization"] = self.authorization
        if self.new_api_user:
            headers["New-Api-User"] = self.new_api_user
        return headers

    def _build_url(self, minutes: int) -> str:
        path = self.endpoint_path or "/api/data/self"
        if not path.startswith("/"):
            path = "/" + path
        url = self.base_domain.rstrip("/") + path

        # è®¡ç®—æ—¶é—´çª—å£ - ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºç»“æŸæ—¶é—´
        end_ts = int(time.time())
        start_ts = end_ts - minutes * 60
        self._last_start_ts = start_ts
        self._last_end_ts = end_ts

        # è¿½åŠ å¼€å§‹/ç»“æŸæ—¶é—´æˆ³ä¸é»˜è®¤ç²’åº¦ï¼ˆå›ºå®šä¸º username=''ï¼Œdefault_time='hour'ï¼‰
        try:
            from urllib.parse import urlsplit, urlunsplit, parse_qsl, urlencode
            split = urlsplit(url)
            q = dict(parse_qsl(split.query, keep_blank_values=True))
            q.update({
                "username": "",
                "start_timestamp": str(start_ts),
                "end_timestamp": str(end_ts),
                "default_time": "hour",
            })
            url = urlunsplit((split.scheme, split.netloc, split.path, urlencode(q), split.fragment))
        except Exception as e:
            if self.log_verbose:
                logger.debug(f"æ„é€ æ—¶é—´æˆ³æŸ¥è¯¢å‚æ•°å¤±è´¥: {e}")
        
        if self.log_verbose:
            # é™„å¸¦å¯è¯»æ—¶é—´çª—å£
            try:
                cst_tz = timezone(timedelta(hours=8))
                def fmt(ts: int) -> str:
                    utc = datetime.fromtimestamp(ts, timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
                    cst = datetime.fromtimestamp(ts, cst_tz).strftime("%Y-%m-%d %H:%M:%S CST+8")
                    return f"{utc} | {cst}"
                win = f"start={start_ts}({fmt(start_ts)}) -> end={end_ts}({fmt(end_ts)})"
            except Exception:
                win = f"start={start_ts} -> end={end_ts}"
            logger.debug(
                f"æ„é€  URL: domain={self.base_domain}, path={path}, url={url}, minutes={minutes}, window={win}"
            )
        return url

    def _build_url_with_range(self, start_ts: int, end_ts: int) -> str:
        path = self.endpoint_path or "/api/data/self"
        if not path.startswith("/"):
            path = "/" + path
        url = self.base_domain.rstrip("/") + path

        self._last_start_ts = int(start_ts)
        self._last_end_ts = int(end_ts)

        try:
            from urllib.parse import urlsplit, urlunsplit, parse_qsl, urlencode
            split = urlsplit(url)
            q = dict(parse_qsl(split.query, keep_blank_values=True))
            q.update({
                "username": "",
                "start_timestamp": str(self._last_start_ts),
                "end_timestamp": str(self._last_end_ts),
                "default_time": "hour",
            })
            url = urlunsplit((split.scheme, split.netloc, split.path, urlencode(q), split.fragment))
        except Exception as e:
            if self.log_verbose:
                logger.debug(f"æ„é€ æ—¶é—´æˆ³æŸ¥è¯¢å‚æ•°å¤±è´¥: {e}")

        if self.log_verbose:
            try:
                cst_tz = timezone(timedelta(hours=8))
                def fmt(ts: int) -> str:
                    utc = datetime.fromtimestamp(ts, timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
                    cst = datetime.fromtimestamp(ts, cst_tz).strftime("%Y-%m-%d %H:%M:%S CST+8")
                    return f"{utc} | {cst}"
                win = f"start={self._last_start_ts}({fmt(self._last_start_ts)}) -> end={self._last_end_ts}({fmt(self._last_end_ts)})"
            except Exception:
                win = f"start={self._last_start_ts} -> end={self._last_end_ts}"
            logger.debug(
                f"æ„é€  URL(æŒ‡å®šèŒƒå›´): domain={self.base_domain}, path={path}, url={url}, window={win}"
            )
        return url

    def _build_log_headers(self) -> Dict[str, str]:
        # ä¸è·å–ç”¨é‡ç›¸åŒçš„é‰´æƒé€»è¾‘
        return self._build_headers()

    def _build_log_url(self, params: Dict[str, Any]) -> str:
        base = self.base_domain.rstrip("/") + "/api/log/"
        try:
            from urllib.parse import urlsplit, urlunsplit, parse_qsl, urlencode
            split = urlsplit(base)
            q = dict(parse_qsl(split.query, keep_blank_values=True))
            # åˆå¹¶ä¼ å…¥æŸ¥è¯¢å‚æ•°
            for k, v in (params or {}).items():
                q[str(k)] = str(v)
            return urlunsplit((split.scheme, split.netloc, split.path, urlencode(q), split.fragment))
        except Exception:
            # ç®€å•æ‹¼æ¥
            try:
                from urllib.parse import urlencode
                return base.rstrip("?") + ("?" + urlencode(params or {}))
            except Exception:
                return base

    async def _fetch_logs(self, params: Dict[str, Any]) -> Any:
        url = self._build_log_url(params)
        headers = self._build_log_headers()
        return await self._http_get_json(url, headers)

    @staticmethod
    def _mask_ip(ip: Any) -> str:
        try:
            s = str(ip or "")
            if not s:
                return "æ— IPä¿¡æ¯"
            parts = s.split(".")
            if len(parts) >= 2:
                return f"{parts[0]}.{parts[1]}.x.x"
            return s
        except Exception:
            return "æ— IPä¿¡æ¯"

    @staticmethod
    def _format_log_type(t: Any) -> str:
        try:
            iv = int(t)
            if iv == 2:
                return "æ¶ˆè´¹"
            if iv == 5:
                return "é”™è¯¯"
            return "å…¶ä»–"
        except Exception:
            return "å…¶ä»–"

    def _extract_log_items(self, payload: Any) -> List[Dict[str, Any]]:
        try:
            if isinstance(payload, list):
                return payload  # type: ignore
            if not isinstance(payload, dict):
                return []
            data = payload.get("data")
            if isinstance(data, dict):
                items = data.get("items") or data.get("list") or []
                if isinstance(items, list):
                    return items  # type: ignore
            # é¡¶å±‚ items/list
            items = payload.get("items") or payload.get("list")
            if isinstance(items, list):
                return items  # type: ignore
            return []
        except Exception:
            return []

    def _format_log_item(self, item: Dict[str, Any]) -> str:
        created_at = 0
        try:
            created_at = int(item.get("created_at", 0) or 0)
        except Exception:
            created_at = 0
        log_time = self._fmt_ts(created_at)
        log_type = self._format_log_type(item.get("type"))
        model = item.get("model_name") or "æœªçŸ¥æ¨¡å‹"
        prompt_tokens = int(item.get("prompt_tokens", 0) or 0)
        completion_tokens = int(item.get("completion_tokens", 0) or 0)
        use_time = int(item.get("use_time", 0) or 0)
        ip_masked = self._mask_ip(item.get("ip"))
        lines = [
            f"ğŸ•’ {log_time}",
            f"ğŸ“Œ {log_type}",
            f"ğŸ¤– {model}",
            f"ğŸ“¥ è¾“å…¥: {prompt_tokens}",
            f"ğŸ“¤ è¾“å‡º: {completion_tokens}",
            f"â±ï¸ è€—æ—¶: {use_time}ms",
            f"ğŸŒ IP: {ip_masked}",
        ]
        return "\n ".join(lines)

    def _build_user_self_url(self) -> str:
        return self.base_domain.rstrip("/") + "/api/user/self"

    async def _fetch_user_self(self) -> Any:
        url = self._build_user_self_url()
        headers = self._build_headers()
        return await self._http_get_json(url, headers)

    def _format_user_self(self, payload: Any) -> str:
        data: Dict[str, Any] = {}
        if isinstance(payload, dict):
            maybe = payload.get("data")
            if isinstance(maybe, dict):
                data = maybe
        username = str(data.get("username") or "-")
        display_name = str(data.get("display_name") or "-")
        group = str(data.get("group") or "-")
        role = int(data.get("role", 0) or 0)
        status = int(data.get("status", 0) or 0)
        request_count = int(data.get("request_count", 0) or 0)
        used_quota = int(data.get("used_quota", 0) or 0)
        quota = int(data.get("quota", 0) or 0)
        current_quota = quota / 500 if quota else 0
        access_token = self._mask_secret(str(data.get("access_token") or ""))
        lines = [
            "--- ç”¨æˆ·ä¿¡æ¯ ---",
            f"ç”¨æˆ·å: {username}",
            f"æ˜µç§°: {display_name}",
            f"åˆ†ç»„: {group}",
            f"è¯·æ±‚æ¬¡æ•°: {request_count:,}",
            f"å·²ç”¨é…é¢: {used_quota:,}",
            f"å½“å‰é¢åº¦(é…é¢/500):$ {current_quota:,}",
        ]
        return "\n".join(lines)

    async def _fetch_payload(self, minutes: int, headers: Dict[str, str], start_ts: Optional[int] = None, end_ts: Optional[int] = None) -> Any:
        """è·å– payloadï¼šä¼˜å…ˆä½¿ç”¨ç»™å®šçš„ [start_ts, end_ts]ï¼›è‹¥æ— åˆ™æŒ‰ minutesï¼›è‹¥ä¸ºç©ºåˆ™å›é€€ç”¨æœ€æ–°è®°å½•é‡æ‹‰ã€‚"""
        # ç¬¬ä¸€æ¬¡ï¼šä¼˜å…ˆä½¿ç”¨æ˜¾å¼æ—¶é—´çª—
        if start_ts is not None and end_ts is not None:
            url = self._build_url_with_range(int(start_ts), int(end_ts))
        else:
            url = self._build_url(minutes)
        payload = await self._http_get_json(url, headers)
        records = self._extract_records(payload)
        if records:
            return payload
        # å›é€€ï¼šä¸å¸¦æ—¶é—´çª—è·å–ä¸€æ¬¡ï¼Œå°è¯•æ‹¿åˆ°æœ€æ–° created_at
        try:
            from urllib.parse import urlsplit, urlunsplit
            split = urlsplit(url)
            url_no_query = urlunsplit((split.scheme, split.netloc, split.path, "", split.fragment))
        except Exception:
            url_no_query = url
        probe = await self._http_get_json(url_no_query, headers)
        probe_records = self._extract_records(probe)
        if not probe_records:
            return payload
        try:
            latest = max(int(r.get("created_at", 0) or 0) for r in probe_records)
            if latest <= 0:
                return payload
            # ç”¨æœ€æ–°è®°å½•æ—¶é—´ä½œä¸º endï¼Œé‡æ–°æ‹‰å–
            self._last_end_ts = latest
            self._last_start_ts = latest - minutes * 60
            # åŸºäº latest æ„é€  URL
            from urllib.parse import urlsplit, urlunsplit, parse_qsl, urlencode
            split = urlsplit(url_no_query)
            q = dict(parse_qsl(split.query, keep_blank_values=True))
            q.update({
                "username": "",
                "start_timestamp": str(self._last_start_ts),
                "end_timestamp": str(self._last_end_ts),
                "default_time": "hour",
            })
            url2 = urlunsplit((split.scheme, split.netloc, split.path, urlencode(q), split.fragment))
            if self.log_verbose:
                logger.debug(f"å›é€€ï¼šåŸºäºæœ€æ–°è®°å½• created_at={latest} é‡æ„ URL å†æ¬¡è¯·æ±‚: {url2}")
            payload2 = await self._http_get_json(url2, headers)
            return payload2
        except Exception as e:
            if self.log_verbose:
                logger.debug(f"å›é€€é‡æ‹‰å¤±è´¥: {e}")
            return payload

    @filter.command("tokensç»Ÿè®¡")
    async def handle_xigua_command(self, event: AstrMessageEvent):
        """å‘½ä»¤ï¼š/tokensç»Ÿè®¡ï¼ˆå›ºå®š 25 å°æ—¶ï¼Œæˆ–æŒ‰é…ç½® time_span_minutesï¼‰"""
        minutes = self.time_span_minutes_default
        # å®æ—¶çª—å£ï¼šä»¥å½“å‰æ—¶åˆ»+1å°æ—¶ä¸º endï¼Œå‘å‰å›æº¯ minutes åˆ†é’Ÿ
        end_ts = int(time.time()) + 3600
        start_ts = end_ts - minutes * 60

        if not self.base_domain:
            text = "é…ç½®ç¼ºå°‘ base_domainï¼ˆä»…åŸŸåï¼Œä¾‹å¦‚ https://new.xigua.wikiï¼‰ï¼Œè¯·åœ¨ _conf_schema.json ä¸­å¡«å†™ã€‚"
            yield event.plain_result(text)
            return

        headers = self._build_headers()
        payload = await self._fetch_payload(minutes, headers, start_ts=start_ts, end_ts=end_ts)
        if self.log_verbose and isinstance(payload, dict):
            logger.debug(f"è¿œç«¯ payload å­—æ®µ: keys={list(payload.keys())[:20]}, success={payload.get('success')}, message={payload.get('message')!r}")

        # è§£æè¿œç«¯è®°å½•
        payload_records = self._extract_records(payload)

        payload_error = None
        if isinstance(payload, dict) and payload.get("error"):
            payload_error = str(payload.get("error"))
            logger.warning(f"è¿œç«¯è¯·æ±‚å¤±è´¥ï¼Œå°†å›é€€è¯»å–æœ¬åœ° data.jsonï¼š{payload_error}")
        else:
            # é»˜è®¤å…ˆä¿å­˜åˆ°æœ¬åœ°ï¼ˆä»…åœ¨è§£æä¸º JSON æ—¶æœ‰æ•ˆï¼‰
            if isinstance(payload, (dict, list)):
                await self._save_raw_json(payload)
            elif self.log_verbose:
                logger.debug("è¿œç«¯å“åº”é JSONï¼Œè·³è¿‡è½ç›˜ï¼Œä»…ä½¿ç”¨æœ¬åœ° data.json å›é€€")

        # è¯»å–æœ¬åœ° data.json
        local_payload = await self._load_local_json()
        if self.log_verbose:
            if isinstance(local_payload, dict):
                logger.debug(f"æœ¬åœ° JSON é¡¶å±‚é”®: {list(local_payload.keys())[:20]}")
            elif isinstance(local_payload, list):
                logger.debug(f"æœ¬åœ° JSON é¡¶å±‚ä¸ºåˆ—è¡¨ï¼Œé•¿åº¦: {len(local_payload)}")
        local_records = self._extract_records(local_payload)
        if self.log_verbose:
            logger.debug(f"æœ¬åœ°è®°å½•æ•°é‡: {len(local_records)}; è¿œç«¯è®°å½•æ•°é‡: {len(payload_records)}")
            if not local_records and isinstance(local_payload, dict):
                logger.debug(f"æœ¬åœ° JSON data/list ä¸ºç©ºï¼Œsuccess={local_payload.get('success')}, message={local_payload.get('message')!r}")

        # ä¼˜å…ˆä½¿ç”¨æœ¬æ¬¡è¯·æ±‚çš„æœ€æ–°è®°å½•ï¼Œè‹¥æ— åˆ™å›é€€æœ¬åœ°
        records = payload_records if payload_records else local_records
        stats, sorted_models = self._analyze(records, start_ts, end_ts, minutes)
        if self.log_verbose:
            logger.debug(
                f"ç»Ÿè®¡: tokens={stats.get('total_tokens_used')}, requests={stats.get('total_requests')}, "
                f"quota={stats.get('total_quota')}, avg_rpm={stats.get('avg_rpm')}, avg_tpm={stats.get('avg_tpm')}"
            )

        report = self._format_report(stats, sorted_models)
        # è‹¥æ— æ•°æ®ï¼Œç»™å‡ºé†’ç›®æç¤º
        if not records:
            report = "[æç¤º] è·å–çš„æ•°æ®ä¸ºç©º\n" + report

        if self.use_forward:
            try:
                nodes = self._build_forward_nodes(report)
                # ç®€å•æ ¡éªŒ forward_uin
                if nodes and getattr(nodes[0], "uin", None):
                    yield event.chain_result(nodes)
                    return
            except Exception:
                pass
        # çº¯æ–‡æœ¬æ¨¡å¼ï¼šä¸ºé¿å…å•æ¡è¿‡é•¿å‘é€å¤±è´¥ï¼Œåˆ‡ç‰‡åˆ†å¤šæ¡å‘é€
        max_len = 900
        text = report or ""
        if not text:
            yield event.plain_result("(ç©º)")
            return
        while text:
            chunk = text[:max_len]
            text = text[max_len:]
            yield event.plain_result(chunk)


    @filter.command("logs")
    async def handle_query_logs_en(self, event: AstrMessageEvent):
        async for result in self._handle_query_logs(event):
            yield result

    async def _handle_query_logs(self, event: AstrMessageEvent):
        # é»˜è®¤ï¼šæœ€è¿‘ 24 å°æ—¶ã€ç¬¬ä¸€é¡µã€20 æ¡ã€type=0
        end_ts = int(time.time())
        start_ts = end_ts - 86400
        params = {
            "p": 1,
            "page_size": self.log_page_size,
            "type": 0,
            "start_timestamp": start_ts,
            "end_timestamp": end_ts,
        }
        yield event.plain_result("æ­£åœ¨æŸ¥è¯¢æœ€è¿‘çš„20æ¡æ—¥å¿—ï¼Œè¯·ç¨å€™...")
        payload = await self._fetch_logs(params)
        items = self._extract_log_items(payload)
        if not items:
            yield event.plain_result("æœªè·å–åˆ°æœ‰æ•ˆæ—¥å¿—æ•°æ®")
            return
        # æ„é€ åˆå¹¶è½¬å‘ï¼ˆå°†æ‰€æœ‰æ—¥å¿—åˆå¹¶åˆ°å•ä¸ªåˆå¹¶è½¬å‘æ¶ˆæ¯ä¸­ï¼‰
        title = "ğŸ“Š æœ€è¿‘20æ¡APIè°ƒç”¨æ—¥å¿—"
        texts: List[str] = [self._format_log_item(it) for it in items]
        combined = "\n\n".join([title] + texts + [f"âœ… å…±æŸ¥è¯¢åˆ° {len(items)} æ¡æ—¥å¿—"])
        if self.log_use_forward:
            try:
                nodes: List[Any] = [self._build_forward_node(combined)]
                yield event.chain_result(nodes)
                return
            except Exception:
                pass
        # å›é€€ä¸ºçº¯æ–‡æœ¬å¤šæ®µå‘é€
        max_len = 900
        text = combined or "(ç©º)"
        while text:
            chunk = text[:max_len]
            text = text[max_len:]
            yield event.plain_result(chunk)

    @filter.command("æŸ¥è¯¢é¢åº¦")
    async def handle_user_self(self, event: AstrMessageEvent):
        """å‘½ä»¤ï¼š/æŸ¥è¯¢é¢åº¦ æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯ï¼ˆ/api/user/selfï¼‰"""
        payload = await self._fetch_user_self()
        # è®°å½•æˆåŠŸ/å¤±è´¥æ—¥å¿—
        if isinstance(payload, dict) and payload.get("success") is True:
            text = self._format_user_self(payload)
        else:
            # å…œåº•æ˜¾ç¤ºåŸå§‹é”™è¯¯
            text = "[æç¤º] è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥\n" + json.dumps(payload, ensure_ascii=False) if isinstance(payload, (dict, list)) else str(payload)
        # å‘é€æ–¹å¼ï¼šæ ¹æ® user_use_forward å†³å®š
        if self.user_use_forward:
            try:
                nodes = [self._build_forward_node(text)]
                yield event.chain_result(nodes)
                return
            except Exception:
                pass
        # çº¯æ–‡æœ¬å‘é€
        max_len = 900
        while text:
            chunk = text[:max_len]
            text = text[max_len:]
            yield event.plain_result(chunk)

    async def terminate(self):
        logger.info("å·²å¸è½½ [XiguaUsageReporter] æ’ä»¶ã€‚")