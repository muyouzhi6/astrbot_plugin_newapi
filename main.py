import asyncio
import json
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Dict, List, Tuple
from urllib.parse import urlencode

import astrbot.api.message_components as Comp
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, filter
from astrbot.api.star import Context, Star, register


@register(
    "newapi",
    "æœ¨æœ‰çŸ¥",
    "NewAPI è¿ç»´åŠ©æ‰‹ï¼šæ¦‚è§ˆ/æ¨¡å‹/æ—¥å¿—/é¢åº¦/å¼‚å¸¸/åˆ†æ/å»ºè®®/å¥åº·ï¼ˆä¸­æ–‡ç®€æŒ‡ä»¤ï¼‰",
    "2.2.0",
)
class NewAPIPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config

        self.base_domain: str = str(config.get("base_domain", "")).strip().rstrip("/")
        self.authorization: str = str(config.get("authorization", "")).strip()
        self.new_api_user: str = str(config.get("new_api_user", "")).strip()
        self.request_timeout: int = int(config.get("request_timeout", 15) or 15)

        self.default_window_hours: int = int(config.get("default_window_hours", 24) or 24)
        self.default_top_n: int = int(config.get("default_top_n", 5) or 5)
        self.default_log_limit: int = int(config.get("log_page_size", 20) or 20)

        self.use_forward: bool = bool(config.get("use_forward", True))
        self.log_use_forward: bool = bool(config.get("log_use_forward", self.use_forward))
        self.user_use_forward: bool = bool(config.get("user_use_forward", False))

        self.llm_enabled: bool = bool(config.get("llm_enabled", False))
        self.llm_use_current_provider: bool = bool(config.get("llm_use_current_provider", True))
        self.llm_provider_id: str = str(config.get("llm_provider_id", "")).strip()

        self._setup_data_paths()

    def _setup_data_paths(self):
        plugin_name = "newapi"
        self.plugin_data_dir = Path(__file__).resolve().parent / "data"
        try:
            from astrbot.core.utils.astrbot_path import get_astrbot_data_path  # type: ignore

            self.plugin_data_dir = get_astrbot_data_path() / "plugin_data" / plugin_name
        except Exception:
            pass
        self.plugin_data_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.plugin_data_dir / "last_usage_payload.json"

    def _headers(self) -> Dict[str, str]:
        h = {"Accept": "application/json"}
        if self.authorization:
            h["Authorization"] = self.authorization
        if self.new_api_user:
            h["New-Api-User"] = self.new_api_user
        return h

    async def _http_get_json(self, url: str, headers: Dict[str, str]) -> Any:
        from urllib.error import HTTPError, URLError
        from urllib.request import Request, urlopen

        def _do() -> Any:
            req = Request(url=url, method="GET")
            for k, v in headers.items():
                req.add_header(k, v)
            with urlopen(req, timeout=self.request_timeout) as resp:
                body = resp.read().decode("utf-8", errors="ignore")
                return json.loads(body)

        try:
            return await asyncio.to_thread(_do)
        except HTTPError as e:
            return {"error": f"HTTP {e.code}"}
        except URLError as e:
            return {"error": f"URL {e.reason}"}
        except Exception as e:
            return {"error": str(e)}

    async def _http_post_json(self, url: str, headers: Dict[str, str], payload: Dict[str, Any], timeout_sec: int) -> Any:
        from urllib.error import HTTPError, URLError
        from urllib.request import Request, urlopen

        def _do() -> Any:
            req = Request(url=url, method="POST")
            for k, v in headers.items():
                req.add_header(k, v)
            data = json.dumps(payload, ensure_ascii=False).encode("utf-8")
            with urlopen(req, data=data, timeout=timeout_sec) as resp:
                body = resp.read().decode("utf-8", errors="ignore")
                return json.loads(body)

        try:
            return await asyncio.to_thread(_do)
        except HTTPError as e:
            return {"error": f"HTTP {e.code}"}
        except URLError as e:
            return {"error": f"URL {e.reason}"}
        except Exception as e:
            return {"error": str(e)}

    def _extract_records(self, payload: Any) -> List[Dict[str, Any]]:
        if isinstance(payload, list):
            return payload
        if not isinstance(payload, dict):
            return []
        if payload.get("success") is False and payload.get("message"):
            logger.warning(f"newapi usage api failed: {payload.get('message')}")
            return []
        for key in ("data", "list", "items"):
            v = payload.get(key)
            if isinstance(v, list):
                return v
            if isinstance(v, dict):
                for k2 in ("data", "list", "items"):
                    vv = v.get(k2)
                    if isinstance(vv, list):
                        return vv
        return []

    def _fmt_ts(self, ts: int) -> str:
        tz = timezone(timedelta(hours=8), name="CST+8")
        return datetime.fromtimestamp(ts, tz).strftime("%m-%d %H:%M")

    def _window(self, hours: int) -> Tuple[int, int]:
        end_ts = int(time.time())
        start_ts = end_ts - int(hours) * 3600
        return start_ts, end_ts

    async def _fetch_usage_payload(self, hours: int) -> Any:
        if not self.base_domain:
            return {"error": "missing base_domain"}
        start_ts, end_ts = self._window(hours)
        q = urlencode(
            {
                "username": "",
                "start_timestamp": str(start_ts),
                "end_timestamp": str(end_ts),
                "default_time": "hour",
            }
        )
        url = f"{self.base_domain}/api/data/self?{q}"
        payload = await self._http_get_json(url, self._headers())
        if isinstance(payload, (dict, list)) and not (isinstance(payload, dict) and payload.get("error")):
            try:
                self.cache_file.write_text(json.dumps(payload, ensure_ascii=False), encoding="utf-8")
            except Exception:
                pass
        return payload

    async def _fetch_logs_payload(self, limit: int, hours: int = 24) -> Any:
        if not self.base_domain:
            return {"error": "missing base_domain"}
        start_ts, end_ts = self._window(hours)
        q = urlencode(
            {
                "p": 1,
                "page_size": max(1, min(limit, 100)),
                "type": 0,
                "start_timestamp": str(start_ts),
                "end_timestamp": str(end_ts),
            }
        )
        url = f"{self.base_domain}/api/log/?{q}"
        return await self._http_get_json(url, self._headers())

    async def _fetch_user_self(self) -> Any:
        if not self.base_domain:
            return {"error": "missing base_domain"}
        return await self._http_get_json(f"{self.base_domain}/api/user/self", self._headers())

    def _aggregate(self, records: List[Dict[str, Any]], start_ts: int, end_ts: int) -> Tuple[Dict[str, Any], List[Tuple[str, Dict[str, int]]]]:
        total_tokens = 0
        total_requests = 0
        total_quota = 0
        model_stats: Dict[str, Dict[str, int]] = {}

        for r in records:
            ts = int(r.get("created_at", 0) or 0)
            if ts < start_ts or ts > end_ts:
                continue
            model = str(r.get("model_name") or "æœªçŸ¥æ¨¡å‹")
            token = int(r.get("token_used", 0) or 0)
            cnt = int(r.get("count", 0) or 0)
            quota = int(r.get("quota", 0) or 0)

            total_tokens += token
            total_requests += cnt
            total_quota += quota

            s = model_stats.setdefault(model, {"token": 0, "count": 0, "quota": 0})
            s["token"] += token
            s["count"] += cnt
            s["quota"] += quota

        minutes = max(1, int((end_ts - start_ts) / 60))
        stats = {
            "start_ts": start_ts,
            "end_ts": end_ts,
            "tokens": total_tokens,
            "requests": total_requests,
            "quota": total_quota,
            "rpm": total_requests / minutes,
            "tpm": total_tokens / minutes,
            "minutes": minutes,
        }
        sorted_models = sorted(model_stats.items(), key=lambda kv: kv[1]["count"], reverse=True)
        return stats, sorted_models

    def _format_overview(self, stats: Dict[str, Any], top_models: List[Tuple[str, Dict[str, int]]], top_n: int) -> str:
        lines = [
            "ğŸ“Š NewAPI æ¦‚è§ˆ",
            f"æ—¶é—´: {self._fmt_ts(stats['start_ts'])} - {self._fmt_ts(stats['end_ts'])}",
            f"æ€» tokens: {stats['tokens']:,}",
            f"æ€»è¯·æ±‚: {stats['requests']:,}",
            f"æ€»é…é¢: {stats['quota']:,}",
            f"å¹³å‡ RPM: {stats['rpm']:.3f}",
            f"å¹³å‡ TPM: {stats['tpm']:.3f}",
        ]
        if top_models and top_n > 0:
            lines.append(f"\nğŸ”¥ Top{top_n} æ¨¡å‹:")
            for i, (m, s) in enumerate(top_models[:top_n], 1):
                lines.append(f"{i}. {m} | è¯·æ±‚{s['count']:,} | token{s['token']:,}")
        return "\n".join(lines)

    def _extract_log_items(self, payload: Any) -> List[Dict[str, Any]]:
        if isinstance(payload, list):
            return payload
        if not isinstance(payload, dict):
            return []
        if payload.get("success") is False and payload.get("message"):
            logger.warning(f"newapi log api failed: {payload.get('message')}")
            return []
        d = payload.get("data")
        if isinstance(d, dict):
            for k in ("items", "list", "data"):
                v = d.get(k)
                if isinstance(v, list):
                    return v
        for k in ("items", "list"):
            v = payload.get(k)
            if isinstance(v, list):
                return v
        return []

    def _format_logs(self, items: List[Dict[str, Any]]) -> str:
        if not items:
            return "ğŸ“œ è°ƒç”¨æ—¥å¿—\næš‚æ— æ•°æ®ï¼ˆå¯èƒ½æ˜¯æ—¶é—´çª—å£å†…æ— è¯·æ±‚æˆ–æ¥å£æœªè¿”å›æ˜ç»†ï¼‰"

        total = len(items)
        err_items = [it for it in items if int(it.get("code", 0) or 0) >= 400 or int(it.get("type", 0) or 0) == 5]
        slow5_items = [it for it in items if int(it.get("use_time", 0) or 0) >= 5000]
        slow15_items = [it for it in items if int(it.get("use_time", 0) or 0) >= 15000]
        avg_use = int(sum(int(it.get("use_time", 0) or 0) for it in items) / max(1, total))

        model_cnt: Dict[str, int] = {}
        for it in items:
            m = str(it.get("model_name") or "æœªçŸ¥æ¨¡å‹")
            model_cnt[m] = model_cnt.get(m, 0) + 1
        top_models = sorted(model_cnt.items(), key=lambda kv: kv[1], reverse=True)[:3]

        out = ["ğŸ“œ è°ƒç”¨æ—¥å¿—æ€»è§ˆ"]
        out.append(
            f"æ€»è¯·æ±‚ {total} | é”™è¯¯ {len(err_items)} ({len(err_items)/max(1,total):.1%}) | "
            f"æ…¢è¯·æ±‚>=5s {len(slow5_items)} | è¶…æ…¢>=15s {len(slow15_items)} | å¹³å‡è€—æ—¶ {avg_use}ms"
        )
        if top_models:
            out.append("ä¸»åŠ›æ¨¡å‹: " + "ï¼Œ".join([f"{m}({c})" for m, c in top_models]))

        out.append("\nğŸ§¾ æœ€è¿‘æ˜ç»†ï¼ˆæ–°â†’æ—§ï¼‰")
        for it in items[:20]:
            t = int(it.get("created_at", 0) or 0)
            m = str(it.get("model_name") or "æœªçŸ¥æ¨¡å‹")
            typ = int(it.get("type", 0) or 0)
            code = int(it.get("code", 0) or 0)
            pt = int(it.get("prompt_tokens", 0) or 0)
            ct = int(it.get("completion_tokens", 0) or 0)
            use = int(it.get("use_time", 0) or 0)

            if typ == 5 or code >= 500:
                icon = "ğŸ”´"
            elif code >= 400:
                icon = "ğŸŸ "
            else:
                icon = "ğŸŸ¢"

            if use >= 15000:
                lat = "ğŸ¢"
            elif use >= 5000:
                lat = "âš ï¸"
            else:
                lat = "âš¡"

            out.append(
                f"{icon} {self._fmt_ts(t)} | {m} | code={code} | {lat}{use}ms | token {pt}/{ct}"
            )

        if total > 20:
            out.append(f"â€¦ å…¶ä½™ {total-20} æ¡å·²çœç•¥ï¼Œå¯ç”¨ /æ—¥å¿— {min(100, total)} æŸ¥çœ‹æ›´å¤š")

        return "\n".join(out)

    def _detect_abnormal(self, items: List[Dict[str, Any]]) -> str:
        if not items:
            return "ğŸš¨ å¼‚å¸¸åˆ†æ\næš‚æ— æ—¥å¿—æ•°æ®ï¼Œæ— æ³•åˆ¤æ–­ã€‚"

        errs: List[Dict[str, Any]] = []
        slow: List[Dict[str, Any]] = []
        model_err: Dict[str, int] = {}

        for it in items:
            code = int(it.get("code", 0) or 0)
            typ = int(it.get("type", 0) or 0)
            use = int(it.get("use_time", 0) or 0)
            m = str(it.get("model_name") or "æœªçŸ¥æ¨¡å‹")
            if typ == 5 or code >= 400:
                errs.append(it)
                model_err[m] = model_err.get(m, 0) + 1
            if use >= 15000:
                slow.append(it)

        total = len(items)
        err_rate = len(errs) / max(1, total)
        slow_rate = len(slow) / max(1, total)

        lines = ["ğŸš¨ å¼‚å¸¸åˆ†æ"]
        lines.append(
            f"æ€»è¯·æ±‚ {total} | é”™è¯¯ {len(errs)} ({err_rate:.1%}) | è¶…æ…¢>=15s {len(slow)} ({slow_rate:.1%})"
        )

        if err_rate >= 0.2:
            lvl = "P0"
            reason = "é”™è¯¯ç‡è¿‡é«˜ï¼Œå·²æ˜¾è‘—å½±å“å¯ç”¨æ€§"
        elif err_rate >= 0.08 or len(slow) >= 5:
            lvl = "P1"
            reason = "ç¨³å®šæ€§é€€åŒ–ï¼Œå»ºè®®å°½å¿«å¤„ç†"
        elif err_rate > 0 or len(slow) > 0:
            lvl = "P2"
            reason = "å­˜åœ¨é›¶æ˜Ÿå¼‚å¸¸ï¼Œå»ºè®®è§‚å¯Ÿå¹¶ä¼˜åŒ–"
        else:
            lvl = "OK"
            reason = "æœªå‘ç°æ˜æ˜¾å¼‚å¸¸"
        lines.append(f"é£é™©ç­‰çº§: {lvl}ï¼ˆ{reason}ï¼‰")

        if model_err:
            top_err = sorted(model_err.items(), key=lambda kv: kv[1], reverse=True)[:3]
            lines.append("é«˜é£é™©æ¨¡å‹: " + "ï¼Œ".join([f"{m}({c})" for m, c in top_err]))

        if errs:
            lines.append("\nğŸ§¯ æœ€è¿‘é”™è¯¯æ ·æœ¬")
            for it in errs[:5]:
                t = int(it.get("created_at", 0) or 0)
                m = str(it.get("model_name") or "æœªçŸ¥æ¨¡å‹")
                code = int(it.get("code", 0) or 0)
                use = int(it.get("use_time", 0) or 0)
                lines.append(f"- {self._fmt_ts(t)} | {m} | code={code} | {use}ms")

        if slow:
            lines.append("\nğŸ¢ è¶…æ…¢æ ·æœ¬")
            for it in slow[:3]:
                t = int(it.get("created_at", 0) or 0)
                m = str(it.get("model_name") or "æœªçŸ¥æ¨¡å‹")
                use = int(it.get("use_time", 0) or 0)
                lines.append(f"- {self._fmt_ts(t)} | {m} | {use}ms")

        lines.append("\nâœ… å»ºè®®åŠ¨ä½œ")
        if lvl in ("P0", "P1"):
            lines.append("1) å…ˆé™åˆ¶å¼‚å¸¸æ¨¡å‹å¹¶åˆ‡æ¢å¤‡ç”¨æ¨¡å‹éªŒè¯")
            lines.append("2) ç¼©çŸ­ max_tokens/é™ä½å¹¶å‘ï¼Œè§‚å¯Ÿ 15 åˆ†é’Ÿ")
            lines.append("3) æŒ‰ code åˆ†ç»„æ’æŸ¥ä¸Šæ¸¸ç½‘å…³ä¸ provider çŠ¶æ€")
        elif lvl == "P2":
            lines.append("1) é’ˆå¯¹æ…¢è¯·æ±‚æ¨¡å‹åšå‚æ•°æ”¶æ•›ï¼ˆmax_tokens/temperatureï¼‰")
            lines.append("2) ä¿æŒç›‘æ§ï¼Œè‹¥é”™è¯¯ç‡å‡è‡³ 8% ä»¥ä¸ŠæŒ‰ P1 å¤„ç†")
        else:
            lines.append("1) å½“å‰å¥åº·ï¼Œå¯ç»§ç»­è§‚å¯Ÿå³°å€¼æ—¶æ®µ")

        return "\n".join(lines)

    async def _llm_analyze(self, event: AstrMessageEvent, title: str, content: str) -> str:
        if not self.llm_enabled:
            return "æœªå¼€å¯ LLM åˆ†æï¼ˆè¯·åœ¨é…ç½®ä¸­å¯ç”¨ llm_enabledï¼‰"

        # é»˜è®¤ä½¿ç”¨å½“å‰ä¼šè¯æœåŠ¡å•†ï¼›å¯åˆ‡æ¢ä¸ºæ‰‹åŠ¨æŒ‡å®š provider
        provider_id = ""
        try:
            if self.llm_use_current_provider:
                provider_id = await self.context.get_current_chat_provider_id(umo=event.unified_msg_origin)
            else:
                provider_id = self.llm_provider_id
        except Exception as e:
            return f"è·å–æœåŠ¡å•†å¤±è´¥: {e}"

        if not provider_id:
            return "LLM æœåŠ¡å•†æœªè®¾ç½®ï¼ˆè¯·æ£€æŸ¥ llm_use_current_provider æˆ– llm_provider_idï¼‰"

        prompt = (
            "ä½ æ˜¯èµ„æ·± NewAPI SRE å€¼ç­å·¥ç¨‹å¸ˆã€‚è¯·åŸºäºè¾“å…¥æ•°æ®è¾“å‡ºã€å¯æ‰§è¡Œã€‘ä¸­æ–‡è¿ç»´ç»“è®ºï¼Œç¦æ­¢ç©ºè¯ã€‚\n\n"
            "è¾“å‡ºå¿…é¡»ä¸¥æ ¼æŒ‰ä»¥ä¸‹ç»“æ„ï¼š\n"
            "# ç»“è®ºæ‘˜è¦\n"
            "- ä¸€å¥è¯åˆ¤æ–­å½“å‰ç³»ç»ŸçŠ¶æ€ï¼ˆå¥åº·/äºšå¥åº·/æ•…éšœï¼‰\n"
            "- å½±å“èŒƒå›´ï¼ˆç”¨æˆ·é¢/æ¨¡å‹é¢/æ—¶æ®µï¼‰\n\n"
            "# å…³é”®å‘ç°ï¼ˆæŒ‰ä¸¥é‡åº¦æ’åºï¼Œæœ€å¤š5æ¡ï¼‰\n"
            "æ¯æ¡æ ¼å¼ï¼š\n"
            "- [P0|P1|P2] ç°è±¡ï½œè¯æ®ï¼ˆå…·ä½“æ•°å€¼ï¼‰ï½œå¯èƒ½æ ¹å› \n\n"
            "# ç«‹å³åŠ¨ä½œï¼ˆ15åˆ†é’Ÿå†…ï¼‰\n"
            "åˆ— 3-5 æ¡å¯ç›´æ¥æ‰§è¡ŒåŠ¨ä½œï¼Œæ¯æ¡éƒ½è¦æœ‰ç›®æ ‡ä¸é¢„æœŸ\n\n"
            "# ä»Šæ—¥ä¼˜åŒ–ï¼ˆå½“å¤©å®Œæˆï¼‰\n"
            "åˆ— 3-5 æ¡ä¼˜åŒ–é¡¹ï¼Œä¼˜å…ˆç¨³å®šæ€§ä¸æˆæœ¬\n\n"
            "# è§‚å¯ŸæŒ‡æ ‡ä¸é˜ˆå€¼\n"
            "è‡³å°‘ç»™å‡ºï¼šé”™è¯¯ç‡ã€P95è€—æ—¶ã€è¶…æ…¢å æ¯”ã€è¯·æ±‚é‡æ³¢åŠ¨é˜ˆå€¼ï¼Œå¹¶å†™æ˜å‘Šè­¦é˜ˆå€¼\n\n"
            "# éœ€è¦è¡¥å……çš„æ•°æ®\n"
            "è‹¥æ•°æ®ä¸è¶³ï¼Œæ˜ç¡®ç¼ºä»€ä¹ˆï¼Œä¸å¾—è‡†æµ‹ã€‚\n\n"
            f"ã€åˆ†æä¸»é¢˜ã€‘{title}\n"
            f"ã€è¾“å…¥æ•°æ®ã€‘\n{content}\n"
        )
        try:
            llm_resp = await self.context.llm_generate(
                chat_provider_id=provider_id,
                prompt=prompt,
            )
            return str(llm_resp.completion_text).strip()
        except Exception as e:
            return f"LLM è°ƒç”¨å¤±è´¥: {e}"

    async def _send_text(self, event: AstrMessageEvent, text: str, use_forward: bool):
        if use_forward:
            try:
                node = Comp.Node(uin=10000, name="newapi", content=[Comp.Plain(text)])
                yield event.chain_result([node])
                return
            except Exception:
                pass
        max_len = 900
        t = text
        while t:
            c = t[:max_len]
            t = t[max_len:]
            yield event.plain_result(c)

    @filter.command("newapi")
    async def cmd_newapi_help(self, event: AstrMessageEvent):
        text = (
            "ğŸ“˜ NewAPI æŒ‡ä»¤\n"
            "/æ¦‚è§ˆ [å°æ—¶]  /æ¨¡å‹ [topN]  /æ—¥å¿— [æ¡æ•°]\n"
            "/é¢åº¦  /å¼‚å¸¸  /åˆ†æ  /å»ºè®®  /å¥åº·\n"
            "\n"
            "ğŸ’¡ LLM æœåŠ¡å•†ï¼š\n"
            "- é»˜è®¤ä½¿ç”¨å½“å‰ä¼šè¯æœåŠ¡å•†ï¼ˆllm_use_current_provider=trueï¼‰\n"
            "- å…³é—­åå¯åœ¨ llm_provider_id ä¸‹æ‹‰æŒ‡å®š"
        )
        async for r in self._send_text(event, text, False):
            yield r

    @filter.command("æ¦‚è§ˆ", alias={"tokensç»Ÿè®¡", "newapiæ¦‚è§ˆ"})
    async def cmd_overview(self, event: AstrMessageEvent, hours: int = 24):
        hours = max(1, min(hours, 168))
        payload = await self._fetch_usage_payload(hours)
        records = self._extract_records(payload)

        # å›é€€æœ¬åœ°ç¼“å­˜
        if not records and self.cache_file.exists():
            try:
                records = self._extract_records(json.loads(self.cache_file.read_text(encoding="utf-8")))
            except Exception:
                pass

        s, e = self._window(hours)
        stats, models = self._aggregate(records, s, e)
        text = self._format_overview(stats, models, self.default_top_n)
        async for r in self._send_text(event, text, self.use_forward):
            yield r

    @filter.command("æ¨¡å‹", alias={"æ¨¡å‹æ’è¡Œ"})
    async def cmd_models(self, event: AstrMessageEvent, topn: int = 5):
        topn = max(1, min(topn, 20))
        payload = await self._fetch_usage_payload(self.default_window_hours)
        records = self._extract_records(payload)
        s, e = self._window(self.default_window_hours)
        stats, models = self._aggregate(records, s, e)
        text = self._format_overview(stats, models, topn)
        async for r in self._send_text(event, text, self.use_forward):
            yield r

    @filter.command("æ—¥å¿—", alias={"logs"})
    async def cmd_logs(self, event: AstrMessageEvent, n: int = 20):
        n = max(1, min(n, 100))
        payload = await self._fetch_logs_payload(n, self.default_window_hours)
        items = self._extract_log_items(payload)
        text = self._format_logs(items)
        async for r in self._send_text(event, text, self.log_use_forward):
            yield r

    @filter.command("é¢åº¦", alias={"æŸ¥è¯¢é¢åº¦"})
    async def cmd_quota(self, event: AstrMessageEvent):
        p = await self._fetch_user_self()
        if isinstance(p, dict) and isinstance(p.get("data"), dict):
            d = p["data"]
            quota = int(d.get("quota", 0) or 0)
            used = int(d.get("used_quota", 0) or 0)
            req = int(d.get("request_count", 0) or 0)
            text = (
                "ğŸ’³ è´¦æˆ·é¢åº¦\n"
                f"ç”¨æˆ·å: {d.get('username', '-') }\n"
                f"åˆ†ç»„: {d.get('group', '-') }\n"
                f"è¯·æ±‚æ¬¡æ•°: {req:,}\n"
                f"å·²ç”¨é…é¢: {used:,}\n"
                f"å½“å‰é¢åº¦(é…é¢/500): $ {quota/500:.2f}"
            )
        else:
            text = f"æŸ¥è¯¢å¤±è´¥: {json.dumps(p, ensure_ascii=False)[:400]}"
        async for r in self._send_text(event, text, self.user_use_forward):
            yield r

    @filter.command("å¼‚å¸¸")
    async def cmd_abnormal(self, event: AstrMessageEvent):
        payload = await self._fetch_logs_payload(max(self.default_log_limit, 30), 24)
        items = self._extract_log_items(payload)
        text = self._detect_abnormal(items)
        async for r in self._send_text(event, text, self.log_use_forward):
            yield r

    @filter.command("åˆ†æ")
    async def cmd_analysis(self, event: AstrMessageEvent):
        usage = await self._fetch_usage_payload(self.default_window_hours)
        logs = await self._fetch_logs_payload(max(self.default_log_limit, 30), 24)
        usage_records = self._extract_records(usage)
        log_items = self._extract_log_items(logs)
        s, e = self._window(self.default_window_hours)
        stats, models = self._aggregate(usage_records, s, e)

        err_cnt = 0
        slow_cnt = 0
        for it in log_items:
            code = int(it.get("code", 0) or 0)
            typ = int(it.get("type", 0) or 0)
            use = int(it.get("use_time", 0) or 0)
            if typ == 5 or code >= 400:
                err_cnt += 1
            if use >= 15000:
                slow_cnt += 1

        brief = {
            "window_hours": self.default_window_hours,
            "summary": {
                "tokens": stats.get("tokens", 0),
                "requests": stats.get("requests", 0),
                "quota": stats.get("quota", 0),
                "rpm": round(float(stats.get("rpm", 0)), 4),
                "tpm": round(float(stats.get("tpm", 0)), 4),
            },
            "top_models": [
                {
                    "model": m,
                    "requests": s.get("count", 0),
                    "tokens": s.get("token", 0),
                    "quota": s.get("quota", 0),
                }
                for m, s in models[:8]
            ],
            "log_snapshot": {
                "total": len(log_items),
                "error_count": err_cnt,
                "error_rate": round(err_cnt / max(1, len(log_items)), 4),
                "slow15s_count": slow_cnt,
                "slow15s_rate": round(slow_cnt / max(1, len(log_items)), 4),
            },
            "recent_errors": [
                {
                    "time": self._fmt_ts(int(it.get("created_at", 0) or 0)),
                    "model": str(it.get("model_name") or "æœªçŸ¥æ¨¡å‹"),
                    "code": int(it.get("code", 0) or 0),
                    "use_time_ms": int(it.get("use_time", 0) or 0),
                }
                for it in log_items
                if int(it.get("type", 0) or 0) == 5 or int(it.get("code", 0) or 0) >= 400
            ][:8],
        }
        text = await self._llm_analyze(event, "è°ƒç”¨åˆ†æ", json.dumps(brief, ensure_ascii=False))
        async for r in self._send_text(event, text, self.use_forward):
            yield r

    @filter.command("å»ºè®®")
    async def cmd_advice(self, event: AstrMessageEvent):
        logs = await self._fetch_logs_payload(max(self.default_log_limit, 50), 24)
        log_items = self._extract_log_items(logs)
        raw = self._detect_abnormal(log_items)
        text = await self._llm_analyze(event, "ä¼˜åŒ–å»ºè®®", raw)
        async for r in self._send_text(event, text, self.use_forward):
            yield r

    @filter.command("å¥åº·", alias={"health"})
    async def cmd_health(self, event: AstrMessageEvent):
        out = ["ğŸ©º å¥åº·æ£€æŸ¥"]
        out.append(f"plugin_version: 2.2.0")
        out.append(f"base_domain: {'OK' if self.base_domain else 'ç¼ºå¤±'}")
        out.append(f"authorization: {'OK' if self.authorization else 'ç¼ºå¤±'}")
        out.append(f"new_api_user: {'OK' if self.new_api_user else 'ç¼ºå¤±'}")

        if self.base_domain:
            p1 = await self._fetch_user_self()
            ok1 = isinstance(p1, dict) and not p1.get('error') and p1.get('success', True)
            out.append(f"/api/user/self: {'OK' if ok1 else 'FAIL'}")
            p2 = await self._fetch_logs_payload(1, 1)
            ok2 = isinstance(p2, dict) and not p2.get('error') and p2.get('success', True)
            out.append(f"/api/log/: {'OK' if ok2 else 'FAIL'}")
            p3 = await self._fetch_usage_payload(1)
            ok3 = isinstance(p3, dict) and not p3.get('error') and p3.get('success', True)
            out.append(f"/api/data/self: {'OK' if ok3 else 'FAIL'}")

        if self.llm_enabled:
            if self.llm_use_current_provider:
                out.append("LLM: å·²å¯ç”¨ï¼ˆä½¿ç”¨å½“å‰ä¼šè¯æœåŠ¡å•†ï¼‰")
            else:
                out.append(f"LLM: å·²å¯ç”¨ï¼ˆæ‰‹åŠ¨æœåŠ¡å•†: {self.llm_provider_id or 'æœªè®¾ç½®'}ï¼‰")
        else:
            out.append("LLM: æœªå¯ç”¨")

        async for r in self._send_text(event, "\n".join(out), False):
            yield r

    async def terminate(self):
        logger.info("newapi æ’ä»¶å·²å¸è½½")
